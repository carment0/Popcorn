{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Rank Matrix Factorization\n",
    "\n",
    "## Formulation\n",
    "Let's assume that our system has $I_{user}$ users and $J_{movie}$ movies. We assign $K_{latent}$ features to each user and movie in the system. We can construct a matrix factorization as follows:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0, 2} & ... & x_{0, K} \\\\\n",
    "x_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "x_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "x_{I,0} & ...     & ...      & ... & x_{I, K}\n",
    "\\end{vmatrix}\n",
    "\\begin{vmatrix}\n",
    "\\theta_{0,0} & \\theta_{0,1} & \\theta_{0, 2} & ... & \\theta_{0, K} \\\\\n",
    "\\theta_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "\\theta_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "\\theta_{J,0} & ...     & ...      & ... & \\theta_{J, K}\n",
    "\\end{vmatrix}^{T}\n",
    "=\n",
    "\\begin{vmatrix}\n",
    "r_{0,0} & r_{0,1} & r_{0, 2} & ... & r_{0, J} \\\\\n",
    "r_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "r_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "r_{I,0} & ...     & ...      & ... & r_{I, J}\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "$X$ represents the latent feature matrix for all users in our system. $\\Theta$ represents the latent feature matrix for all all movies in our system. The matrix product of $X$ and $\\Theta^{T}$ is the model predicated rating. \n",
    "\n",
    "$$\n",
    "X\\Theta^{T} = \\hat{R}\n",
    "$$\n",
    "\n",
    "Let $R$ represents the actual rating we received from the MovieLens dataset. For every missing value in $R$, we will place them with average rating each movie received from the poll of users. Then we define the loss function as follows:\n",
    "\n",
    "$$\n",
    "L_{X, \\Theta} = \\frac{1}{2}\\Sigma_{i,j} (X\\Theta^{T} - R)^{2} + \\frac{\\lambda}{2}\\Sigma_{i, k}X^{2} + \\frac{\\lambda}{2}\\Sigma_{j, k}\\Theta^{2}\n",
    "$$\n",
    "\n",
    "The optimization objective here is to minimize the loss function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Derivatives & Gradients\n",
    "\n",
    "Recall that the output of our low-rank matrices model is $\\hat{R}$ and let's find the gradient of $L$ with respect to $\\hat{R}$ first. The $\\frac{1}{2}$ term will get canceled out by the square term.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{R}} = \\hat{R} - R\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{R} = X\\Theta^{T}\n",
    "$$\n",
    "\n",
    "Now let's figure out the gradient of $\\hat{R}$ with respect to $X$ and $\\Theta$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{R}}{\\partial X} = \\Theta^{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{R}}{\\partial \\Theta} = X\n",
    "$$\n",
    "\n",
    "Using chain rule, we can then derive the following results:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial \\hat{R}}\\frac{\\partial \\hat{R}}{\\partial X}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\Theta} = \\frac{\\partial L}{\\partial \\hat{R}}\\frac{\\partial \\hat{R}}{\\partial \\Theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "```python\n",
    "\"\"\"Denote U as the user latent feature matrix and M as the movie latent feature matrix\"\"\"\n",
    "model_pred = np.dot(U, M.T)\n",
    "\n",
    "grad_pred = model_pred - R \n",
    "grad_u = np.dot(grad_pred, M) + (reg * U)\n",
    "grad_m = np.dot(grad_pred.T, U) + (reg * M)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def loss(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute loss\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    diff = np.dot(U, M.T) - R\n",
    "    loss = 0.5 * np.sum(diff * diff)\n",
    "    loss += reg * np.sum(U * U) / 2\n",
    "    loss += reg * np.sum(M * M) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rel_error(X, Y):\n",
    "    \"\"\"Compute maximum relative error\n",
    "    \n",
    "    :param X: Matrix of the same shape as Y\n",
    "    :type X: numpy array\n",
    "    :param Y: Matrix of the same shape as X\n",
    "    :type Y: numpy array\n",
    "    \"\"\"\n",
    "    return np.max(np.abs(X - Y) / (np.maximum(1e-8, np.abs(X) + np.abs(Y))))\n",
    "\n",
    "\n",
    "def compute_grad(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    u_grad = np.zeros(U.shape)\n",
    "    m_grad = np.zeros(M.shape)\n",
    "    \n",
    "    num_user, lat_dim = U.shape\n",
    "    num_movie, lat_dim = M.shape\n",
    "    \n",
    "    diff = np.dot(U, M.T) - R\n",
    "    for i in range(num_user):\n",
    "        u_grad[i] = np.sum(diff[i].reshape(num_movie, 1) * M, axis=0) + (reg * U[i])\n",
    "\n",
    "    for j in range(num_movie):\n",
    "        m_grad[j] = np.sum(diff.T[j].reshape(num_user, 1) * U, axis=0) + (reg * M[j])\n",
    "        \n",
    "    return u_grad, m_grad\n",
    "\n",
    "\n",
    "def compute_grad_vectorized(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    grad_out = np.dot(U, M.T) - R \n",
    "    grad_u = np.dot(grad_out, M)+ (reg * U)\n",
    "    grad_m = np.dot(grad_out.T, U) + (reg * M)\n",
    "    return grad_u, grad_m\n",
    "\n",
    "\n",
    "def compute_num_grad(U, M, R, loss_func, reg=0.0, h=1e-5):\n",
    "    \"\"\"Compute numerical gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    num_grad_u = np.zeros(U.shape)\n",
    "    num_grad_m = np.zeros(M.shape)\n",
    "    \n",
    "    U_dim, L_dim = U.shape\n",
    "    M_dim, L_dim = M.shape\n",
    "    \n",
    "    for i in range(U_dim):\n",
    "        for k in range(L_dim):\n",
    "            old_val = U[i][k]\n",
    "            \n",
    "            U[i][k] = old_val + h\n",
    "            fuph = loss_func(U, M, R, reg)\n",
    "            \n",
    "            U[i][k] = old_val - h\n",
    "            fumh = loss_func(U, M, R, reg)\n",
    "            \n",
    "            U[i][k] = old_val\n",
    "            num_grad_u[i][k] = (fuph - fumh) / (2 * h)\n",
    "    \n",
    "    for j in range(M_dim):\n",
    "        for k in range(L_dim):\n",
    "            old_val = M[j][k]\n",
    "            \n",
    "            M[j][k] = old_val + h\n",
    "            fmph = loss_func(U, M, R, reg)\n",
    "            \n",
    "            M[j][k] = old_val - h\n",
    "            fmmh = loss_func(U, M, R, reg)\n",
    "            \n",
    "            M[j][k] = old_val\n",
    "            num_grad_m[j][k] = (fmph - fmmh) / (2 * h)\n",
    "    \n",
    "    return num_grad_u, num_grad_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterative implementation\n",
      "\n",
      "Gradient of U relative error 1.5257047735033336e-09\n",
      "Gradient of M relative error 1.7025272054379865e-09\n",
      "\n",
      "Fully vectorized implementation\n",
      "\n",
      "Gradient of U relative error 1.5257045748323983e-09\n",
      "Gradient of M relative error 1.7025272054379865e-09\n"
     ]
    }
   ],
   "source": [
    "num_user = 5\n",
    "num_movie = 10\n",
    "lat_dim = 10\n",
    "reg = 0.1\n",
    "\n",
    "np.random.seed(0)\n",
    "R = np.random.rand(num_user, num_movie) * 5\n",
    "U = np.random.rand(num_user, lat_dim)\n",
    "M = np.random.randn(num_movie, lat_dim)\n",
    "\n",
    "np.dot(U, M.T)\n",
    "\n",
    "grad_u, grad_m = compute_grad(U, M, R, reg)\n",
    "num_grad_u, num_grad_m = compute_num_grad(U, M, R, loss, reg)\n",
    "\n",
    "print \"\\nIterative implementation\\n\"                                                                                                                                                                                                                \n",
    "print \"Gradient of U relative error %s\" % str(rel_error(grad_u, num_grad_u))\n",
    "print \"Gradient of M relative error %s\" % str(rel_error(grad_m, num_grad_m))\n",
    "\n",
    "print \"\\nFully vectorized implementation\\n\"\n",
    "grad_u, grad_m = compute_grad_vectorized(U, M, R, reg)\n",
    "print \"Gradient of U relative error %s\" % str(rel_error(grad_u, num_grad_u))\n",
    "print \"Gradient of M relative error %s\" % str(rel_error(grad_m, num_grad_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44cbd90b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction:\n",
      "[[2.74453558 3.5730624  3.0013782  2.72495306 2.07634872 3.22343667\n",
      "  2.16867417 4.40479659 4.75925313 1.95241956]\n",
      " [3.93110101 2.65246219 2.81375603 4.58581008 0.35362361 0.4780791\n",
      "  0.12669202 4.14591792 3.86561675 4.29266286]\n",
      " [4.83346695 3.95758285 2.31372635 3.87466965 0.60928358 3.15844329\n",
      "  0.72523497 4.68932701 2.63658184 2.08560523]\n",
      " [1.35017893 3.83396737 2.28135232 2.82940949 0.1291836  3.05680769\n",
      "  3.0107386  3.0909186  4.68444611 3.36702171]\n",
      " [1.78355249 2.173264   3.43614197 0.32010237 3.2775662  3.31310629\n",
      "  1.05220428 0.67575537 1.58832707 1.79163532]]\n",
      "\n",
      "\n",
      "Actual Rating:\n",
      "[[2.74406752 3.57594683 3.01381688 2.72441591 2.118274   3.22947057\n",
      "  2.18793606 4.458865   4.8183138  1.91720759]\n",
      " [3.95862519 2.6444746  2.84022281 4.62798319 0.35518029 0.4356465\n",
      "  0.10109199 4.16309923 3.89078375 4.35006074]\n",
      " [4.89309171 3.99579282 2.30739681 3.90264588 0.59137213 3.19960511\n",
      "  0.71676644 4.72334459 2.60924161 2.0733097 ]\n",
      " [1.32277806 3.87116845 2.28075166 2.84216974 0.093949   3.08817749\n",
      "  3.06047861 3.08466998 4.71874039 3.4091015 ]\n",
      " [1.7975395  2.18515977 3.48815598 0.30112736 3.33383358 3.35318935\n",
      "  1.05191281 0.64463149 1.57714175 1.81855385]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps = 1000\n",
    "learning_rate = 5e-2\n",
    "losses = []\n",
    "\n",
    "for step in range(steps):\n",
    "    losses.append(loss(U, M, R, reg))\n",
    "    grad_u, grad_m = compute_grad(U, M, R, reg)\n",
    "    U = U - learning_rate * grad_u\n",
    "    M = M - learning_rate * grad_m\n",
    "    \n",
    "plt.plot(list(range(steps)), losses, 'o-')\n",
    "plt.show()\n",
    "\n",
    "print \"Model Prediction:\"\n",
    "print np.dot(U, M.T)\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Actual Rating:\"\n",
    "print R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a new user\n",
    "\n",
    "Suppose that we are given a new user, we can perform the same type of training on this user except that we are not modifying the movie features; we will only modify the new user's preference vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44cbe51ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction:\n",
      "[[ 0.71172833  1.02241052  1.71358824 -0.02672381  2.17991451  1.69306215\n",
      "   0.82948497  0.9881572   1.50015334  0.15329032]]\n",
      "\n",
      "\n",
      "Actual Rating:\n",
      "[[2.03620586 1.16117071 0.66243817 0.26713591 3.62797182 0.05713729\n",
      "  3.85290374 0.73473323 0.39761041 0.44801517]]\n"
     ]
    }
   ],
   "source": [
    "single_user_matrix = np.random.rand(1, lat_dim)\n",
    "single_user_rating = np.random.rand(1, num_movie) * 5\n",
    "losses = []\n",
    "learning_rate = 5e-2\n",
    "\n",
    "steps = 1000\n",
    "for step in range(steps):\n",
    "    losses.append(loss(single_user_matrix, M, single_user_rating, reg))\n",
    "    grad_u, _ = compute_grad(single_user_matrix, M, single_user_rating, reg)\n",
    "    single_user_matrix = single_user_matrix - learning_rate * grad_u\n",
    "    \n",
    "plt.plot(list(range(steps)), losses, 'o-')\n",
    "plt.show()\n",
    "\n",
    "print \"Model Prediction:\"\n",
    "print np.dot(single_user_matrix, M.T)\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Actual Rating:\"\n",
    "print single_user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all this is a linear model, it does have difficulty with fitting random data perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
